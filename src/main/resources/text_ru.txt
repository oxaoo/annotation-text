Анализ основных этапов поиска
Если бы можно было вернуться в прошлое (например, в 1998 год), какие основные этапы нам пришлось бы пройти тогда, чтобы проделать работу по построению поисковой системы? 
Сегодня эти этапы остаются теми же, какими они были в 1998 году, но мы повысили их результативность и вычислительную производительность. 
Основные этапы традиционной процедуры поиска:
• Краулинг
• Синтаксический разбор
• Анализ 
• Индексирование
Краулинг – это процесс сбора документов, по которым мы хотим выполнять поиск. Возможно, этот этап не нужен, если документы уже существуют или включены в коллекцию. Синтаксический разбор необходим для преобразования документов (XML, HTML, Word, PDF) в простую структуру, которая обеспечит представление полей индексирования исключительно в виде текста.

Обзор компонентов поискового робота.
Поисковые роботы (crawlers) предназначены для обнаружения, загрузки и сохранения контента Интернета. Как мы видели в главе 2, поисковый робот является частью более крупного приложения, такого как 
поисковая система.
Типичный поисковый робот включает следующие компоненты:
•	Модуль, обслуживающий хранилище всех известных роботу url-адресов
•	Модуль загрузки документов, который извлекает документы из интернета по предоставленному набору url-адресов
•	Модуль, обслуживающий хранилище метаданных и контента, извлеченных из оригинальных загруженных документов в процессе совершаемого роботом обхода
Структура и реализация отдельных компонентов зависит от того, что вы планируете обходить, и от масштаба обработки, которую должен осуществить робот. Для обхода веб-сайтов сети интранет также можно обойтись довольно простой реализацией. Эти узлы могут быть распределенными даже с точки зрения их географического местоположения, чтобы быть ближе к источнику данных. 
